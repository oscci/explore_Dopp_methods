---
title: "Analysis for A2 writeup"
author: "Dorothy Bishop/ Zoe Woodhead / Paul Thompson"
date: "27 Jul 2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


```

`r Sys.time()`

## Background
See Dopp_explore_log.RMd for more background on how Modeling was developed.

Source reference is: Kline, R. B. (2011). Principles and practice of structural equation Modeling, 3rd edition. New York: Guilford Press.
Kline has detailed discussion of testing for fit: is against absolute cutoffs, though notes cutoffs that have been proposed on basis of simulation studies.

RMSEA is absolute index of (badness of) Model fit: aim for below .08.
This value decreases with more DF (greater parsimony) or larger sample size.
 
Comparative fit index (CFI) measures relative improvement in fit of Model over baseline Model. 
Computed as 1 - (chisqM - dfM)/(chisqB-dfB); Good fit if CDI > .95 (see Kline p 208)

##Chunks of code for setting packages and reading in data 
from SEM2_maxLikelihood_realdata.R
```{r packages, warning=FALSE, message=FALSE}
#Needs OpenMx, which you get with following command (not CRAN)
#Hmm - having problems with OpenMx - now using Cran version

#source('https://openmx.ssri.psu.edu/software/getOpenMx.R')
require(tidyverse)
require(OpenMx)
require(stargazer) #simple commands for nice tables
require(semTools) #for fit measures
library(DiagrammeR) #for the diagram
require(stringr)
require(data.table)
library('devtools')
library("reshape2")
library("yarrr")


```
##Code for setting directory flexibly
```{r definedir}
thisuser <-'dorothybishop'
thisdrive<- '' #may need to set this to 'C:' for PC users
#readdir <-paste0(thisdrive,'/Users/',thisuser,'/Dropbox/project A2/')
readdir<-'' #use this if working directory set to folder with all the data
```

```{r participants}
particdat<-read.csv('A2_Participant_Info.csv')

#Participant descriptors reported in paper
print('Gender x handedness')
table(particdat$Gender,particdat$handedness)
ageyr<-particdat$Age_m/12
print('Age in yr')
summary(ageyr)
```

##Task performance data
```{r behaviouraldata}
behavdat<-read.csv('A2_Behavioural_Data.csv')
behavdat<-behavdat[1:30,] #remove some blank lines at end of file
stargazer(behavdat[,2:5],type='text')

acc.cols<-c(7,10,13,16,19,22,25,28)
rt.cols<-acc.cols+1
#accuracy data on tasks B,C, E and F - stargazer for quick check
print('Percentages correct')
stargazer(behavdat[,acc.cols],type='text')
print('RT')
stargazer(behavdat[,rt.cols],type='text')

#make data frame to hold data formatted for paper
behavdf<-data.frame(matrix(NA,nrow=4,ncol=8))
colnames(behavdf)<-c('%corr.1','%corr.2','t','p','RT.1','RT.2','t','p')
#get means and SDs for table
mymeanp<-round(sapply(behavdat[,acc.cols],mean,na.rm=TRUE),1)
mysdp<-round(sapply(behavdat[,acc.cols],sd,na.rm=TRUE),2)
mymeanr<-round(sapply(behavdat[,rt.cols],mean,na.rm=TRUE),2)
mysdr<-round(sapply(behavdat[,rt.cols],sd,na.rm=TRUE),2)
for (i in 1:4){
  
behavdf[i,1]<-paste0(mymeanp[i],' (',mysdp[i],')')
behavdf[i,2]<-paste0(mymeanp[(i+4)],' (',mysdp[i+4],')')
behavdf[i,5]<-paste0(mymeanr[i],' (',mysdr[i],')')
behavdf[i,6]<-paste0(mymeanr[(i+4)],' (',mysdr[i+4],')')
thist<-t.test(behavdat[,acc.cols[i]],behavdat[,acc.cols[i+4]],paired=TRUE)
behavdf[i,3]<-round(thist$statistic,2)
behavdf[i,4]<-round(thist$p.value,3)
thist2<-t.test(behavdat[,rt.cols[i]],behavdat[,rt.cols[i+4]],paired=TRUE)
behavdf[i,7]<-round(thist2$statistic,2)
behavdf[i,8]<-round(thist2$p.value,3)
}
rownames(behavdf)<-c('B','C','E','F')
write.table(behavdf, "Behavtable.txt", sep="\t",row.names=TRUE,quote=FALSE) #Currently this is table 1
```
##Code for reading and reshaping LI data
```{r readdata}
#read in data from sessions 1 and 2, having saved as .csv
#NB. Need to set working directory to location of data files - or else specify path

data1<-read.csv('Results_Session1.csv')
data2<-read.csv('Results_Session2.csv')



alltaskall <- cbind(select(data1,A1.LI_mean,B1.LI_mean,C1.LI_mean,D1.LI_mean,E1.LI_mean,F1.LI_mean),
             select(data2,A2.LI_mean,B2.LI_mean,C2.LI_mean,D2.LI_mean,E2.LI_mean,F2.LI_mean))
mylabels<-c('ListGen1','PhonDec1','SemDec1','SentGen1','SentComp1','Jabber1',
            'ListGen2','PhonDec2','SemDec2','SentGen2','SentComp2','Jabber2')
colnames(alltaskall)<-mylabels
head(alltaskall)
```



##Code for identifying exclusions and substituting NA based on SE
Please see justification in Methods. This differs from what we preregistered but I think we can defend it as making more sense.

```{r excludeSE}
alltask<-alltaskall #create a new copy where the outliers will be coded as NA
allse <- cbind(select(data1,A1.mean_se,B1.mean_se,C1.mean_se,D1.mean_se,E1.mean_se,F1.mean_se),
             select(data2,A2.mean_se,B2.mean_se,C2.mean_se,D2.mean_se,E2.mean_se,F2.mean_se))

myse<-c(allse[,1],allse[,2],allse[,3],allse[,4],allse[,5],allse[,6],
        allse[,7],allse[,8],allse[,9],allse[,10],allse[,11],allse[,12])

Q3<-quantile(myse,.75)
Q1<-quantile(myse,.25)
Qlimit<-Q3+2.2*(Q3-Q1)
secols<-colnames(allse)
dropSE<-0 #initialise counter
for (i in 1:12){
w<-which(allse[,i]>Qlimit)
if (length(w)>0){
alltask[w,i]<-NA
dropSE<-dropSE+1
}
}
print(paste('Dropped because high SE, N = ',dropSE))
#picks up subject 5 on PHondec1, and subject 9 on Jabber1

#Now remove those with fewer than 12 trials in a condition
dropN<-0 #initialise counter
nbit<-c('A1.N','B1.N','C1.N','D1.N','E1.N','F1.N')
for (i in 1:6){
  w<-which(colnames(data1)==nbit[i])
  ww<-which(data1[,w]<12)
  if(length(ww>0)){
    alltask[ww,i]<-NA
    dropN<-dropN+1
  }
}

nbit<-c('A2.N','B2.N','C2.N','D2.N','E2.N','F2.N')
for (i in 1:6){
  w<-which(colnames(data2)==nbit[i])
  ww<-which(data2[,w]<12)
  if(length(ww>0)){
    alltask[ww,(i+6)]<-NA
     dropN<-dropN+1
  }
}
print(paste('Dropped because < 12 trials, N = ',dropN))  
  
#Dropped data points are S13 Sentgen2, S14 Listgen2, S26 Sentcomp1 and S30 Sentgen1
```
##Show means etc for tasks with time1 and time2 adjacent
```{r stargaze}
stargazer(alltask[,c(1,7,2,8,3,9,4,10,5,11,6,12)],type='text')
```
##Check normality of data
Have a look at the densities and do Shapiro-Wilks test and QQ plot
 Plots will be written to the working directory, called densities 1-6
```{r normalcheck}
for (i in 1:6){
 # png(filename=paste0("densities_",i,".png"))
  par(mfrow=c(2,2))
  for (j in 1:2){
    offset<- 6*(j-1)
  tempdata<-alltask[,(i+offset)]
  myshap<-shapiro.test(tempdata)
   plot(density(tempdata,na.rm=TRUE),main=mylabels[(i+offset)],xlim=c(-6,8),ylim=c(0,.3))
   text(-4,.1,paste('mean = \n',round(mean(tempdata,na.rm=TRUE),2)))
## Plot using a qqplot
   qqnorm(tempdata);qqline(tempdata, col = 2)
   text(.4,0,paste('Shapiro\np = ',round(myshap$p.value,3)))
  }
 # dev.off()
}
```
##Pirateplot

```{r dopirate}

#First do one sample t-tests to check if sig different from zero
tdf<-data.frame(matrix(NA,nrow=12,ncol=5))
colnames(tdf)<-c('t','p','labelht','label','task')
ilist<-c(1,7,2,8,3,9,4,10,5,11,6,12)
for (j in 1:12){
  i<-ilist[j]
  myt<-t.test(alltask[,i])
  tdf[j,1]<-round(myt$statistic,2)
  tdf[j,2]<-round(myt$p.value,3)
  tdf[j,3]<-max(alltask[,i],na.rm=TRUE)+1
  tdf[j,4]<-''
  if(myt$p.value<.05){tdf[j,4]<-"*"}
    if(myt$p.value<.01){tdf[j,4]<-"**"}
    if(myt$p.value<.001){tdf[j,4]<-"***"}
  tdf[j,5]<-colnames(alltask)[i]
}

# Melt cleverly reshapes LI_data into a long format using ID 
# (the only factor) as the categorical variable    
LI_long <- melt(alltask) #version with outliers removed
LI_long$ID<-rep(1:30,6)
LI_long$Session<-c(rep(1,180),rep(2,180))
LI_long$Task<-c(rep('A',30),rep('B',30),rep('C',30),rep('D',30),rep('E',30),rep('F',30),
                rep('A',30),rep('B',30),rep('C',30),rep('D',30),rep('E',30),rep('F',30)) 
colnames(LI_long)[2]<-'LI'
png(filename="LIpirateA2.png", width=1500, height=1200,res=300)
#par(mai = c(.5, .8, .05, 0.05))# mai specifies bottom, left, top and right margins in inches

# Make pirate plot
pirateplot(formula = LI ~ Session + Task,
           data = LI_long,
           main = "",
           ylim = c(-5, 8),
           point.o=.5,inf.f.o=.1,inf.b.o=0,
           jitter.val=.075)

 abline(h=0,lty=2)
 
 xmarker_nums <- c(1,2,4,5,7,8,10,11,13,14,16,17) # For plotting x-axis
 
# Mark significant differences from one sample ttest with black asterisks
text(xmarker_nums, y=as.numeric(tdf[,3]), labels=tdf[,4],font=2, cex=1)
 dev.off()


```

![Pirate plot](LIpirateA2.png)


#Correlation matrix as heatmap
```{r corrheat}

png(filename="heatmap.png", width=1500, height=1500,res=300)
cormat<-round(cor(alltask[,ilist], use="pairwise.complete.obs", method="pearson"),2)
rownames(cormat)<-c('A1','A2','B1','B2','C1','C2','D1','D2','E1','E2','F1','F2')
colnames(cormat)<-c('A1','A2','B1','B2','C1','C2','D1','D2','E1','E2','F1','F2')
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
}

upper_tri <- get_upper_tri(cormat)

melted_cormat <- melt(upper_tri,na.rm=T)
#for some reason NA values remain: need to remove these or they create grey cells
#w<-which(is.na(melted_cormat[,3]))
#melted_cormat<-melted_cormat[-w,]

colnames(melted_cormat)[1:2]<-c('Var1','Var2') #names of cols 1 and 2
# Create correlation heatmap using ggplot
ggheatmap <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(colour = "white")+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal()+ 
  theme(axis.text.x = element_text(vjust = 1, 
                                   size = 12, hjust = 0.5),
        axis.text.y = element_text(vjust = 0.5, 
                                   size = 12, hjust = 1))+
  coord_fixed()

#add some formatting
ggheatmap + 
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.ticks = element_blank(),
    legend.justification = c(1, 0),
    legend.position = c(0.5, 0.7),
    legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 9, barheight = 1.5,
                               title.position = "top", title.hjust = 0.5))

dev.off()
```

![Heatmap](heatmap.png)
##Structural equation Models: 

Start with Models of means


```{r dropone}
#This bit of script was used at the start of OpenMx in case we wanted to try 'drop one' approach
#to test consistency of bifactor solution. It will drop cases specified in thisdrop.
#Could do this in a loop once we have an optimal approach.
thisdrop <- 0 #specify a number for participant to be dropped (1 to 30)
  dataRaw      <- mxData( observed=alltask, type="raw" )
 if(thisdrop>0){
   dataRaw      <- mxData( observed=alltask[-thisdrop,], type="raw" )}
  

```
###Free Means and Vars Model 
(from fig 4 in prereg document)

This acts as baseline: it just Models means and variance: no relation between variables, 
and no consistency in LI over time.

We can then test how other Models fit when we introduce constraints by
equalising paths or by Modeling covariances.

N.B. I previously described this as a saturated Model, but the fully saturated Model includes covariances
(which are all zero) and so has more DF. The free means Model can be evaluated against the fully saturated one, using mxRefModels to specify the saturated Model. When that is done, we get rmsea and CFI provided for relative fit.
```{r setupbigsummary}
#We'll create a Table, bigsummary, to hold fit stats for different Models
bigsummary <- data.frame(matrix(NA,nrow=1,ncol=10))
bigsummary[1,2]<-0 #add a value so we recognise empty dataframe when adding first row
colnames(bigsummary)<-c('-2LL','df','CFI','RMSEA','Comparison','chi.diff','chi.df','p','BIC','Summary')
  #Also important to clear previous models to avoid errors
 rm(Model1fit)
  rm(Model2fit)
# rm(biFactorFit)
# rm(biFactorFitb)
# rm(oneFactorFit)
```

```{r define.addbig}
#This function will add a row to bigsummary for each new Model
addbig <- function(thissummary,mycomp,thiscomment,thisrowname) {
  
myLL<-round(thissummary$Minus2LogLikelihood,1)
mydf<-thissummary$degreesOfFreedom
mychi<-round(thissummary$Chi,1)
mydfdiff<-thissummary$ChiDoF
myp<-round(thissummary$p,3)
if (myp<.001){myp<-'<.001'}
myBIC<- round(thissummary$BIC.Mx,1)
myCFI<-round(thissummary$CFI,1)
myRMSEA<-round(thissummary$RMSEA,3)

thisrow<-nrow(bigsummary)
if(bigsummary[thisrow,2]>0){thisrow<-thisrow+1}
bigsummary[thisrow,]<-c(myLL,mydf,myCFI,myRMSEA,mycomp,mychi,mydfdiff,myp,myBIC,thiscomment)
rownames(bigsummary)[thisrow]<-thisrowname
return(bigsummary)
}
```


```{r freemeans_Model1}
# residual variances

resVars      <- mxPath( from=mylabels, arrows=2,
                        free=TRUE, values=rep(1,12), #estimate error variances; free to vary by test and occasion
                        labels=c("e1","e2","e3","e4","e5","e6","e7","e8","e9","e10","e11","e12") )
# each has a different name, meaning they are estimated with different values
# means
means        <- mxPath( from="one", to=mylabels, arrows=1,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels =mylabels ) 
myModel1 <- mxModel("Free means Model", type="RAM",
                    manifestVars=mylabels,
                    dataRaw, resVars,  means)
Model1Fit <- mxRun(myModel1)
summary.Model1<-summary(Model1Fit, refModels=mxRefModels(Model1Fit, run = TRUE)) #gives CFI, TLI, RMSEA if refModels specified
summary.Model1
#Define labels to add to bigtable
mycomp<-'Saturated'
thiscomment<-'Free means/vars'
thisrowname<-'1.Independent data'
bigsummary<-addbig(summary.Model1,mycomp,thiscomment,thisrowname) 
#Note that the Model has 24 parameters (i.e. 12 means and 12 vars), but the Saturated Model has 90, as it
#also includes all the covariances between 12 variables.

```

N.B. The summary output shows estimates of variances (e) and means (M). Note that the variance is particularly high for SentGen2. Suggests we might want to look at this to see if our outlier exclusion has missed noisy cases. Also v low variance for ListGen1

## Model 2: Tweak free means Model to check stability of means
 Means and variances set to be the same for time1 and time2 for each measure. 
 This is achieved by giving the path the same name, e.g. meanA for A1 and A2
 N.B. This is not same as test-retest reliability: as covariances not considered.
 We're just testing if the mean values are similar time 1 and time 2, not whether same people are high or low.
```{r Model2}
# residual variances
resVars      <- mxPath( from=mylabels, arrows=2,
                        free=TRUE, values=rep(1,12), #estimate error variances; same for each test on time 1 and time 2
                        labels=c("e1","e2","e3","e4","e5","e6","e1","e2","e3","e4","e5","e6") )
# means
means        <- mxPath( from="one", to=mylabels, arrows=1,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels =c("meanA","meanB","meanC",
                                  "meanD","meanE","meanF",
                                  "meanA","meanB","meanC",
                                  "meanD","meanE","meanF") ) 
myModel2 <- mxModel("Stability Model", type="RAM",
                     manifestVars=mylabels,
                     dataRaw, resVars,  means)
Model2Fit <- mxRun(myModel2)
summary.Model2<-summary(Model2Fit, refModels=mxRefModels(Model2Fit, run = TRUE)) 

#to get correct values for chi sq etc for model comparison run comparison and plug in values from row 2
test.1.2<-mxCompare(Model1Fit,Model2Fit)
summary.Model2$Chi<-test.1.2$diffLL[2]
summary.Model2$ChiDoF<-test.1.2$diffdf[2]
summary.Model2$p<-test.1.2$p[2]
mycomp<-'Model 1'
thiscomment<-'Equal means/vars'
thisrowname<-'2. Stable task effect'
bigsummary<-addbig(summary.Model2,mycomp,thiscomment,thisrowname) 

# Make a message (pmessage) that tells us what the Model comparison tells us. 
# Here we are looking for a nonsignificant p-value: that tells us that despite having fewer estimated parameters, fit does not suffer
# df is N observations (nsub*nvalues = 28*12) minus N estimated parameters (ep)
pmessage<-'Model 2 fit deteriorates relative to Model 1! Means differ across test occasions' #default message
if(test.1.2$p[2]>.05){
  pmessage <- 'Model 2 fit does not deteriorate relative to Model 1; ie means/vars equivalent across test occasions'}

pmessage

```
## Model where all tests equivalent: Model 3
More extreme version of stability Model, where all means and all vars are the same.
This tests (rather implausible!) hypothesis that all measures are similarly lateralised. It is equivalent to the 'population bias' Model.
We expect fit to worsen relative to stability Model - assuming measures differ in extent of laterality.
```{r Model3}
# residual variances
resVars      <- mxPath( from=mylabels, arrows=2,
                        free=TRUE, values=rep(1,12), #estimate error variances; same for each test on time 1 and time 2
                        labels=c("e1","e1","e1","e1","e1","e1","e1","e1","e1","e1","e1","e1") )
# means
means        <- mxPath( from="one", to=mylabels, arrows=1,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels =c("meanA","meanA","meanA",
                                  "meanA","meanA","meanA","meanA","meanA","meanA",
                                  "meanA","meanA","meanA") ) 
myModel3 <- mxModel("Model3", type="RAM",
                     manifestVars=mylabels,
                     dataRaw, resVars,  means)

Model3Fit <- mxRun(myModel3) #The mxRun command evaluates the Model.
summary.Model3<-summary(Model3Fit, refModels=mxRefModels(Model3Fit, run = TRUE)) 

#to get correct values for chi sq etc for model comparison run comparison and plug in values from row 2
#NB Model with most DF is last; Model 3 has many DF because no task-specific terms

test.3.2<-mxCompare(Model2Fit,Model3Fit)
summary.Model3$Chi<-test.3.2$diffLL[2]
summary.Model3$ChiDoF<-test.3.2$diffdf[2]
summary.Model3$p<-test.3.2$p[2]
mycomp<-'Model 2'
thiscomment<-'All means/vars equal'
thisrowname<-'3. Population bias'
bigsummary<-addbig(summary.Model3,mycomp,thiscomment,thisrowname) 

#We predict that means differ, in which case p will be < .05
pmessage<-'Means do not differ between tasks' #default
if(test.2.3$p[2]<.05){pmessage <- 'Means differ between tasks'}

pmessage
bigsummary
```
##Test dorsal/ventral/mixed Model (Model 4)
This proposes pattern of means different for taskAB, C and DEF (Model 2a in prereg document).
Model predicts strength of laterality will be: AB > DEF > C.
We test this by equating means and variances for AB and DEF.

```{r dorsalventral}
# residual variances
resVars      <- mxPath( from=mylabels, arrows=2,
                        free=TRUE, values=rep(1,12), #estimate error variances; same for each test on time 1 and time 2
                        labels=c("e1","e1","e2","e3","e3","e3","e1","e1","e2","e3","e3","e3") )
# means
means        <- mxPath( from="one", to=mylabels, arrows=1,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels =c("meanAB","meanAB","meanC",
                                  "meanDEF","meanDEF","meanDEF",
                                  "meanAB","meanAB","meanC",
                                  "meanDEF","meanDEF","meanDEF") ) 
myModel4 <- mxModel("Model4", type="RAM",
                     manifestVars=mylabels,
                     dataRaw, resVars,  means)

Model4Fit <- mxRun(myModel4) #The mxRun command evaluates the Model.
summary4<-summary(Model4Fit)
summary4
#NB comparison is between Models 2 and 4
myLLdiff<-round(summary4$Minus2LogLikelihood-summary2$Minus2LogLikelihood,1) #NB subtracting prior LL before changing it
mydfdiff<-summary4$degreesOfFreedom-summary2$degreesOfFreedom
myLL<-round(summary4$Minus2LogLikelihood,1)
mydf<-summary4$degreesOfFreedom
myp<-round(pchisq(myLLdiff, df=mydfdiff,lower.tail=FALSE),3)
myCFI<-NA
myrmsea<-NA

BIC4 <- round(summary4$BIC.Mx,1)
bigsummary[4,] <-c(myLL,mydf,'2 vs 4',myLLdiff,mydfdiff,myp,BIC4,myCFI,myrmsea,'AB>DEF>C')
rownames(bigsummary)[4]<-'4.Dorsal/ventral stream'

#Add some output showing the mean estimates and testing if they fit the expected pattern
my4<-summary(Model4Fit)$parameters[4:6,c(1,5,6)]
qmessage<-'Model predicts AB > DEF > C'
rmessage<-'Not confirmed'
if((my4[1,2]>my4[3,2])&&(my4[3,2]>my4[2,2])){rmessage<-'Confirmed'}

pmessage
qmessage
rmessage
my4
bigsummary
```
##Lexical retrieval Model
Hypothesis A.2 Strength of lateralization depends on the extent to which tasks require lexical retrieval (more lexical retrieval = stronger left lateralization).

Operationalised by setting means equal for tasks BD, ACF and E (Model 5)

```{r lexical retrieval}
# residual variances
resVars      <- mxPath( from=mylabels, arrows=2,
                        free=TRUE, values=rep(1,12), #estimate error variances; same for each test on time 1 and time 2
                        labels=c("e1","e2","e1","e2","e3","e2","e1","e2","e1","e2","e3","e2") )
# means
means        <- mxPath( from="one", to=mylabels, arrows=1,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels =c("meanACF","meanBD","meanACF",
                                  "meanBD","meanE","meanACF",
                                  "meanACF","meanBD","meanACF",
                                  "meanBD","meanE","meanACF") ) 
myModel5 <- mxModel("Model5", type="RAM",
                     manifestVars=mylabels,
                     dataRaw, resVars,  means)

Model5Fit <- mxRun(myModel5) #The mxRun command evaluates the Model.
summary5<-summary(Model5Fit)
summary5
#NB comparison is between Models 2 and 4
myLLdiff<-round(summary5$Minus2LogLikelihood-summary2$Minus2LogLikelihood,1) #NB subtracting prior LL before changing it
mydfdiff<-summary5$degreesOfFreedom-summary2$degreesOfFreedom
myLL<-round(summary5$Minus2LogLikelihood,1)
mydf<-summary5$degreesOfFreedom
myp<-round(pchisq(myLLdiff, df=mydfdiff,lower.tail=FALSE),3)
myCFI<-NA
myrmsea<-NA

BIC5 <- round(summary5$BIC.Mx,1)
bigsummary[5,] <-c(myLL,mydf,'2 vs 5',myLLdiff,mydfdiff,myp,BIC5,myCFI,myrmsea,'BD>ACF')
rownames(bigsummary)[5]<-'5.LexicalRetrieval'

#compare with  stability Model (Model2) where task means free to vary
Model5test<-mxCompare(Model2Fit,Model5Fit)
Model5test
pmessage<-'Model5 fits as well as Model with means free to vary any way'
if(Model5test$p[2]<.05){
  pmessage <- paste0('Model5 (BIC=',BIC5,') is worse fit than Model with means not constrained (BIC=',BIC2,')')
   }
#Add some output showing the mean estimates and testing if they fit the expected pattern
my5<-summary(Model5Fit)$parameters[4:6,c(1,5,6)] #pull out just the rows/cols of interest
qmessage<-'Model predicts BD > ACF'
rmessage<-'Not confirmed'
if(my5[2,2]>my5[1,2]){rmessage<-'Confirmed'}
Model5test
pmessage
qmessage
rmessage
my5
bigsummary
```



##SEM Models including covariances
Single factor Model (means equalized for T1 and T2).
If tasks are correlated (as they are) this will give a better fit than the preceding Models, which only looks at means.
It is necessary to scale the paths from observed variables to latent factor in terms of one of the observed variables. We chose the first variable. NB I have checked that choice does not affect the factor solution.

```{r Factor1}
# residual variances
resVars      <- mxPath( from=mylabels, arrows=2,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels=c("e1","e2","e3","e4","e5","e6","e1","e2","e3","e4","e5","e6") )

# latent variance - Factor1 is the single factor
latVar       <- mxPath( from="Factor1", arrows=2,
                        free=TRUE, values=1, labels ="varFactor1" )
# factor loadings
facLoads     <- mxPath( from="Factor1", to=mylabels, arrows=1,
                        free=c(FALSE,TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,TRUE,TRUE,TRUE,TRUE,TRUE), 
                        values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels =c("l1","l2","l3","l4","l5","l6","l1","l2","l3","l4","l5","l6") )#same for each test on time 1 and 2
#The first path is fixed at one - others scaled relative to this

# means - one extra mean for the Factor, but this is set to NA
means        <- mxPath( from="one", to=c(mylabels,'Factor1'), arrows=1,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T,FALSE), values=c(1,1,1,1,1,1,1,1,1,1,1,1,0),
                        labels =c("meanA","meanB","meanC",
                                  "meanD","meanE","meanF","meanA","meanB","meanC",
                                  "meanD","meanE","meanF",NA) ) #means constant from time 1 to time 2

oneFactorModel <- mxModel("Single Factor Model", type="RAM",
                          manifestVars=mylabels, latentVars="Factor1",
                          dataRaw, resVars, latVar, facLoads, means)

oneFactorFit<-mxRun(oneFactorModel)
#summary(oneFactorFit) #uncomment this to see results
summary6<-summary(oneFactorFit)
summary6
#NB comparison is between Models 2 and 4a
myLLdiff<-round(summary2$Minus2LogLikelihood-summary6$Minus2LogLikelihood,1) #NB subtracting prior LL before changing it
mydfdiff<-summary2$degreesOfFreedom-summary6$degreesOfFreedom
myLL<-round(summary6$Minus2LogLikelihood,1)
mydf<-summary6$degreesOfFreedom
myp<-round(pchisq(myLLdiff, df=mydfdiff,lower.tail=FALSE),3)
d.baseModel<-as.numeric(bigsummary$LLdiff[2])-as.numeric(bigsummary$chi.df[2])
d.Model6<-myLLdiff-mydfdiff
myCFI<-round((d.baseModel-d.Model6)/d.baseModel,3)
myrmsea<-round(sqrt(myLLdiff-mydfdiff)/sqrt(mydfdiff*(summary6$numObs-1)),3)

BIC6 <- round(summary6$BIC.Mx,1)
bigsummary[6,] <-c(myLL,mydf,'2 vs 6',myLLdiff,mydfdiff,myp,BIC6,myCFI,myrmsea,'Covariances: one factor')
rownames(bigsummary)[6]<-'6. Person effect'


#compare with  Model where no correlation between measures
Model6test<-mxCompare(oneFactorFit,Model2Fit)
Model6test


pmessage<-'One factor Model no better than Model with no covariance between measures'
if(Model6test$p[2]<.05){
  pmessage <- paste0('One factor Model (BIC=',BIC6,') is better fit than Model with no covariance between measures (BIC=',BIC2,')')
}
pmessage
bigsummary

```
Note how the CFI is now in a more sensible range, but still is well below acceptable level.
Will a bifactor Model improve this?

##Bifactor Model
Here we specify two independent latent factors. Aim is to see whether the tests form two clusters.
```{r bifactor}
# residual variances
resVars      <- mxPath( from=mylabels, arrows=2,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels=c("e1","e2","e3","e4","e5","e6","e1","e2","e3","e4","e5","e6") )

# latent variances and covariance: NB assume totally independent, so covariance fixed at zero
latVars      <- mxPath( from=c("Factor1","Factor2"), arrows=2, connect="unique.pairs",
                        free=c(T,F,F), values=c(1,0,1), labels=c("varFactor1","cov","varFactor2") )
#changed the free statement from free =c(T,T,T) (that was error in prereg script: gives underidentified Model)

# factor loadings for Factor1 #NB test A loading is fixed to one for this factor
facLoadsFactor1     <- mxPath( from="Factor1", to=mylabels, arrows=1,
                               free=c(FALSE,TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,TRUE,TRUE,TRUE,TRUE,TRUE), 
                               values=rep(1,12),
                               labels =c("k1","k2","k3","k4","k5","k6","k1","k2","k3","k4","k5","k6") )

# factor loadings for Factor2 #NB test A loading is fixed to zero for this factor
facLoadsFactor2     <- mxPath( from="Factor2", to=mylabels, arrows=1,
                               free=c(FALSE,TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,TRUE,TRUE,TRUE,TRUE,TRUE), 
                               values=c(0,rep(1,5),0,rep(1,5)),
                               labels =c("l1","l2","l3","l4","l5","l6","l1","l2","l3","l4","l5","l6") )

# means #estimated for all except the two factors
means        <- mxPath( from="one", to=c(mylabels,'Factor1','Factor2'), arrows=1,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T,FALSE,FALSE), values=c(1,1,1,1,1,1,1,1,1,1,1,1,0,0),
                        labels =c("meanA","meanB","meanC",
                                  "meanD","meanE","meanF","meanA","meanB","meanC",
                                  "meanD","meanE","meanF",NA,NA) )

biFactorModel <- mxModel("BiFactor Model", type="RAM",
                          manifestVars=mylabels,
                          latentVars=c("Factor1","Factor2"),
                          dataRaw, resVars, latVars, facLoadsFactor1, facLoadsFactor2, means)

biFactorFit <- mxRun(biFactorModel)
summary7 <-summary(biFactorFit)
summary7
#NB comparison is between Models 6 and 7
myLLdiff<-round(summary6$Minus2LogLikelihood-summary7$Minus2LogLikelihood,1) 
mydfdiff<-summary6$degreesOfFreedom-summary7$degreesOfFreedom
myLL<-round(summary7$Minus2LogLikelihood,1)
mydf<-summary7$degreesOfFreedom
myp<-round(pchisq(myLLdiff, df=mydfdiff,lower.tail=FALSE),3)
d.baseModel<-d.Model6 #ie Model from prior section
d.Model7<-myLLdiff-mydfdiff
myCFI<-round((d.baseModel-d.Model7)/d.baseModel,3)
myrmsea<-round(sqrt(myLLdiff-mydfdiff)/sqrt(mydfdiff*(summary7$numObs-1)),3)

BIC7 <- round(summary7$BIC.Mx,1)
bigsummary[7,] <-c(myLL,mydf,'6 vs 7',myLLdiff,mydfdiff,myp,BIC7,myCFI,myrmsea,'Covariances: bifactor')
rownames(bigsummary)[7]<-'7. Person x task effect'

mcomp<-mxCompare(biFactorFit,oneFactorFit)
pmessage<-'Bi-factor Model does not improve fit over one factor Model'

if (mcomp$p[2]<.05){pmessage <- paste0('Bi-factor Model (BIC=',BIC7,') is better fit than one factor Model (BIC=',BIC6,')')}
pmessage
mcomp
bigsummary
#mxCheckIdentification(biFactorModel, details=TRUE) # check Model identification: all OK

```
Better fit for bifactor than for single factor, though CFI is still below accepted value for good fit. 
To explore reasons for poor fit, can look at differences between expected and observed covariances.

## Explore reasons for poor fit
We can extract the observed covariance matrix and compare it with the expected values from the current Model. If we take the difference between these, we can identify whether there are particular covariances that are problematic.
```{r covexplore}
mymat.e<-mxGetExpected(biFactorFit,"covariance")
mymat.o <- cov(alltask,use="pairwise.complete.obs")
mymat.d<-abs(mymat.e-mymat.o) #absolute size of mismatch between obs and expected
mymat.d1<-mymat.e-mymat.o #size of mismatch with sign
cc<-rainbow(ncol(mymat.d1))
heatmap(mymat.d1,keep.dendro=FALSE,Rowv=NA,Colv=NA,
        revC=TRUE,col = cm.colors(256),margins=c(5,5),
        main='Signed diff exp/obs cov')
```

Dark colours (pink or blue) indicate lack of agreement between obs and expected (neg or positive). Note the heat map show dark pink on the diagonal for SentGen1 and PhonDec2. This means that the observed variance for these measures is lower than the Model predicts. The corresponding diagonal blocks for SentGen2 and PhonDec1 are darkish blue: this is because we have set the estimated variances for the time 1 and time 2 tests to be the same (so based on average); so if observed value at one time is higher than the estimate, the estimate for the other time will be lower. When we look at the observed values in the stargazer table above, we can see that there are relatively large differences in variances for time1 and time2 for these two tasks. We can tweak one line of the Model, to allow these variances to differ, and re-run. The fit does then improve. 
(We achieve this by just giving a different label to the path - see below)

resVars      <- mxPath( from=mylabels, arrows=2,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels=c("e1","e2","e3","e4","e5","e6","e1","e12","e3","e14","e5","e6") )
                        
Given that this worked well, I went further and allowed the variance terms to vary across sessions for all variables. We then get further improvement of fit.

Here is the Model with those settings:
##Bifactor Model with unconstrained variances for T1 and T2
```{r bifactor2}
doextra<-1
if(doextra==1){
  #keep all the same except for resVars
resVars      <- mxPath( from=mylabels, arrows=2,
                        free=c(T,T,T,T,T,T,T,T,T,T,T,T), values=c(1,1,1,1,1,1,1,1,1,1,1,1),
                        labels=c("e1","e2","e3","e4","e5","e6","e11","e12","e13","e14","e15","e16") )

biFactorModelb <- mxModel("BiFactor Modelb", type="RAM",
                          manifestVars=mylabels,
                          latentVars=c("Factor1","Factor2"),
                          dataRaw, resVars, latVars, facLoadsFactor1, facLoadsFactor2, means)

biFactorFitb <- mxRun(biFactorModelb)
summary8<-summary(biFactorFitb)

summary8
#NB comparison is between Models 6 and 8
myLLdiff<-round(summary6$Minus2LogLikelihood-summary8$Minus2LogLikelihood,1) 
mydfdiff<-summary6$degreesOfFreedom-summary8$degreesOfFreedom
myLL<-round(summary8$Minus2LogLikelihood,1)
mydf<-summary8$degreesOfFreedom
myp<-round(pchisq(myLLdiff, df=mydfdiff,lower.tail=FALSE),3)
d.baseModel<-d.Model6 #ie Model from prior section
d.Model8<-myLLdiff-mydfdiff
myCFI<-round((d.baseModel-d.Model8)/d.baseModel,3)
myrmsea<-round(sqrt(myLLdiff-mydfdiff)/sqrt(mydfdiff*(summary7$numObs-1)),3)

BIC8 <- round(summary8$BIC.Mx,1)
bigsummary[8,] <-c(myLL,mydf,'6 vs 8',myLLdiff,mydfdiff,myp,BIC8,myCFI,myrmsea,'Covariances: bifactor.free vars')
rownames(bigsummary)[7]<-'7. Person x task effect2'
mysummary<-summary8$parameters[1:10,c(1,3:6)]
mysummary$z<-mysummary$Estimate/mysummary$Std.Error
mcomp<-mxCompare(biFactorFitb,oneFactorFit)
pmessage<-'Bi-factor Modelb does not improve fit over one factor Model'

pmessage <- paste0('Bi-factor Modelb (BIC=',BIC8,') is better fit than one factor Model (BIC=',BIC6,')')

if (mcomp$p[2]<.05){psummary <-'Bi-factor Modelb gives better fit than one factor Model'}
pmessage
mcomp
bigsummary
}
```
NB We ought to do the same for variances for one-factor Model, otherwise it is an unfair comparison?

Next chunk just redoes the heatmap for the new Model.

```{r covexplore2}
if(doextra==1){
  mymat.e<-mxGetExpected(biFactorFitb,"covariance")
mymat.o <- cov(alltask,use="pairwise.complete.obs")
mymat.d<-abs(mymat.e-mymat.o) #absolute size of mismatch between obs and expected
mymat.d1<-mymat.e-mymat.o #size of mismatch with sign
cc<-rainbow(ncol(mymat.d1))
heatmap(mymat.d1,keep.dendro=FALSE,Rowv=NA,Colv=NA,
        revC=TRUE,col = cm.colors(256),margins=c(5,5),
        main='Signed diff exp/obs cov')
}
```

## Draw simplified path diagram
Draw diagram of the bi-factor Model, with nonsignificant paths omitted.
N.B. The file for_graphviz is set up in advance and read in and modified according to results. For this part of the script to work you must have the file 'for_graphviz.csv' in your working directory.

Test A is shown in red as this has fixed paths to X1 (1) and X2 (0).

NB If this figure is published, need to make following points:

* This is simplified path diagram. It shows just one measure per variable, when in fact there were two, and it does not show means, though these were estimated.

* Also nonsignificant paths are omitted.
```{r drawpaths}
require(stringr)
# omxGraphviz(biFactorModel, dotFilename = "bifactor.dot")
# grViz("bifactor.dot") #this will generate a .dot file but it
# is messy, as it shows time 1 and time 2 measures, as well as means

# Script below shows time1/time2 combined and omits means for clarity
mybit<-read.csv('for_graphviz.csv',stringsAsFactors = FALSE,header=FALSE) #full list of all paths.
mybit2<-print.data.frame(mybit, 
                 quote=FALSE) #get rid of quotes

#we now want to a) remove rows that are NS and b) put in path coeffs for the rest
thisrow<-12 #NB: first row with path specification is col 13
thatrow<-0 #counter for the summary z scores: NB these exclude measure A! 
for (j in 1:2){#each *factor* (not each test occasion - these are collapsed in diagram)

for (i in 1:6){ #each task 
    thisrow<-thisrow+1

    if(i>1){ #measure A is fixed so not in the table
      thatrow<-thatrow+1
    if(mysummary$z[thatrow]<1.96)
    {mybit2[thisrow,]<-''} #delete this one
    else{
      pathlabel<-round(mysummary$Estimate[thatrow],2)
      bb<-mybit2[thisrow,]
      bb<-str_replace(bb,'xx',as.character(pathlabel))
      mybit2[thisrow,]<-bb
    }
    } #loop to here when i is 1: no action
  }
}
mybit2[19,]<-'' #delete path for A to X2: this one was fixed to 0
dotFilename<-'dottry.dot'
write.table(mybit2, dotFilename, append = FALSE,
            row.names = FALSE, col.names = FALSE,quote=FALSE)

grViz(dotFilename)

```

##Session information
```{r sessinfo}
sessionInfo()
```